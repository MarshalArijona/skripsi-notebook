{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "n_classes = 10\n",
    "#dimension of z or latent representation\n",
    "z_dimension = 10\n",
    "#dimension of X or data\n",
    "X_dimension = 784\n",
    "#dimension of label of data\n",
    "y_dimension = 10\n",
    "\n",
    "TRAIN_BATCH_SIZE = 100\n",
    "VALID_BATCH_SIZE = 1000\n",
    "EPOCHS = 1000\n",
    "N = 1000\n",
    "TINY_ERROR = 1e-15\n",
    "DATA_PATH = \"/floyd/input/skripsi_datasets_2/\"\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "training_reconstruction_loss = []\n",
    "training_generator_loss = []\n",
    "training_discriminator_loss = []\n",
    "training_generator_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_dimension, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, z_dimension)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x_gauss = self.layer3(x)\n",
    "        \n",
    "        return x_gauss\n",
    "\n",
    "class Decoder_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dimension, N)\n",
    "        self.layer2 = nn.Linear(N,N)\n",
    "        self.layer3 = nn.Linear(N,X_dimension)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.5, training=self.training)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return F.sigmoid(x)\n",
    "\n",
    "class Discriminator_net_gauss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_net_gauss, self).__init__()\n",
    "        self.layer1 = nn.Linear(z_dimension, N)\n",
    "        self.layer2 = nn.Linear(N, N)\n",
    "        self.layer3 = nn.Linear(N, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.layer1(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.layer2(x), p=0.5, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return F.sigmoid(self.layer3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/subMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48be84f882244485bd7fa84ad4ab0899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/subMNIST/raw/train-images-idx3-ubyte.gz to ../data/subMNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/subMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36724630b3e645b4971cc561826189d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/subMNIST/raw/train-labels-idx1-ubyte.gz to ../data/subMNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/subMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4491ab7fca4f1990cffcdf7bdb29d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/subMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/subMNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/subMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a548ee94f5419688c761ace4aad551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/subMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/subMNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_labeled = pickle.load(open(DATA_PATH + \"train_labeled.p\", \"rb\"))\n",
    "trainset_unlabeled = pickle.load(open(DATA_PATH + \"train_unlabeled.p\", \"rb\"))\n",
    "# Set -1 as labels for unlabeled data\n",
    "trainset_unlabeled._train_labels = torch.from_numpy(np.array([-1] * 47000))\n",
    "validset = pickle.load(open(DATA_PATH + \"validation.p\", \"rb\"))\n",
    "train_labeled_loader = torch.utils.data.DataLoader(trainset_labeled,\n",
    "                                                       batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "train_unlabeled_loader = torch.utils.data.DataLoader(trainset_unlabeled,\n",
    "                                                         batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                         shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=VALID_BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(decoder, encoder, discriminator_gauss, decoder_optimizer, encoder_optimizer, generator_optimizer, discriminator_optimizer, data_loader):\n",
    "    encoder = encoder.train()\n",
    "    decoder = decoder.train()\n",
    "    discriminator_gauss.train()\n",
    "    \n",
    "    discriminator_loss = None\n",
    "    generator_loss = None\n",
    "    reconstruction_loss = None\n",
    "    \n",
    "    for X, target in data_loader:\n",
    "        X = X * 0.3081 + 0.1307\n",
    "        X = X.resize(TRAIN_BATCH_SIZE, X_dimension)\n",
    "        X, target = Variable(X), Variable(target)\n",
    "        \n",
    "        if is_cuda:\n",
    "            X, target = X.cuda(cuda), target.cuda(cuda)\n",
    "            \n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "        \n",
    "        #reconstruction phase\n",
    "        z_sample = encoder(X)\n",
    "        X_sample = decoder(z_sample)\n",
    "        compared_with_original = X.resize(TRAIN_BATCH_SIZE, X_dimension)\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        reconstruction_loss = mse_loss(X_sample + TINY_ERROR, compared_with_original + TINY_ERROR)\n",
    "        \n",
    "        reconstruction_loss.backward()\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "        \n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "        \n",
    "        #regularization phase\n",
    "        #Train Discriminator\n",
    "        encoder = encoder.eval()\n",
    "        z_real_gauss = Variable(torch.empty(TRAIN_BATCH_SIZE, z_dimension).normal_(mean=0, std=1.0))\n",
    "        \n",
    "        if is_cuda:\n",
    "            z_real_gauss = z_real_gauss.cuda(cuda)\n",
    "        \n",
    "        z_fake_gauss = encoder(X)\n",
    "        \n",
    "        discriminator_real_gauss = discriminator_gauss(z_real_gauss)\n",
    "        discriminator_fake_gauss = discriminator_gauss(z_fake_gauss)\n",
    "        \n",
    "        discriminator_loss = 0.5 * (torch.mean((discriminator_real_gauss + TINY_ERROR - 1)**2) + torch.mean((discriminator_fake_gauss + TINY_ERROR)**2))\n",
    "        \n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        discriminator_gauss.zero_grad()\n",
    "        \n",
    "        #Train Generator\n",
    "        encoder = encoder.train()\n",
    "        z_fake_gauss = encoder(X)\n",
    "        \n",
    "        generator_fake_gauss = discriminator_gauss(z_fake_gauss)\n",
    "        generator_loss = 0.5 * torch.mean((generator_fake_gauss + TINY_ERROR - 1)**2)\n",
    "\n",
    "        \n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "    return discriminator_loss, generator_loss, reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_labeled_loader, train_unlabeled_loader, valid_loader):\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    if is_cuda:\n",
    "        encoder = Encoder_net().cuda(cuda)\n",
    "        decoder = Decoder_net().cuda(cuda)\n",
    "        discriminator_gauss = Discriminator_net_gauss().cuda(cuda)\n",
    "    else:\n",
    "        encoder = Encoder_net()\n",
    "        decoder = Decoder_net()\n",
    "        discriminator_gauss = Discriminator_net_gauss()\n",
    "\n",
    "    #learning rates for optimization\n",
    "    learning_rate_1 = 0.0001\n",
    "    learning_rate_2 = 0.00005\n",
    "\n",
    "    #optimization for decoder and encoder\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate_1)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate_1)\n",
    "\n",
    "    generator_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate_2)\n",
    "    discriminator_optimizer = optim.Adam(discriminator_gauss.parameters(), lr=learning_rate_2)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        discriminator_loss, generator_loss, reconstruction_loss = train_one_epoch(decoder, encoder, discriminator_gauss, \n",
    "                                                                              decoder_optimizer, encoder_optimizer, generator_optimizer, \n",
    "                                                                              discriminator_optimizer, train_unlabeled_loader)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        if epoch % 10 == 0:\n",
    "            training_reconstruction_loss.append(reconstruction_loss)\n",
    "            training_generator_loss.append(generator_loss)\n",
    "            training_discriminator_loss.append(discriminator_loss)\n",
    "            print('Epoch-{}, Time-{:.2}, Discriminator_loss-{:.4}, Generator_loss-{:.4}, reconstruction_loss-{:.4}'.format(epoch, epoch_time, discriminator_loss.item(), generator_loss.item(), reconstruction_loss.item()))\n",
    "    \n",
    "        if epoch % 20 == 0:\n",
    "            encoder = encoder.eval()\n",
    "            decoder = decoder.eval()\n",
    "            discriminator_gauss = discriminator_gauss.eval()\n",
    "            \n",
    "            X_test = None\n",
    "            y_test = None\n",
    "\n",
    "            for X, target in valid_loader:\n",
    "                X_test = X\n",
    "                y_test = target\n",
    "                break\n",
    "\n",
    "            if is_cuda:\n",
    "                X_test = X_test.cuda(cuda)\n",
    "                \n",
    "            X_test = X_test.resize(VALID_BATCH_SIZE, X_dimension) \n",
    "            \n",
    "            list_y_test = []\n",
    "            for item in y_test:\n",
    "                list_y_test.append(item.item())\n",
    "            \n",
    "            encoded_X_test = encoder(X_test)\n",
    "            training_generator_sample.append(encoded_X_test)\n",
    "            target_list = list_y_test\n",
    "\n",
    "            figure = plt.figure()\n",
    "            set_classes = set(target_list)\n",
    "            color_map = plt.cm.rainbow(np.linspace(0, 1, len(set_classes)))\n",
    "            axis = plt.subplot(111, aspect='equal')\n",
    "            box = axis.get_position()\n",
    "            axis.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            handles = [mpatches.Circle((0, 0), label=class_, color=color_map[i]) for i, class_ in enumerate(set_classes)]\n",
    "            axis.legend(handles=handles, shadow=True, bbox_to_anchor=(1.05, 0.45), fancybox=True, loc='center left')\n",
    "            kwargs = {'alpha': 0.8, 'c': [color_map[i] for i in target_list]}\n",
    "            encoded_X_test_cpu = encoded_X_test.cpu()\n",
    "            plt.scatter(encoded_X_test_cpu[:, 0].detach().numpy(), encoded_X_test_cpu[:, 1].detach().numpy(), s = 2, **kwargs)\n",
    "            axis.set_xlim([-10, 10])\n",
    "            axis.set_ylim([-30, 30])\n",
    "\n",
    "            plt.savefig('latent_space_standard_aae_least/epoch_%d.png' % epoch)\n",
    "            plt.close('all')\n",
    "\n",
    "            n_digits = 20\n",
    "            decoded_X_test = decoder(encoder(X_test[:n_digits]))\n",
    "            decoded_X_test_cpu = decoded_X_test.cpu()\n",
    "            decoded_X_test_cpu = np.reshape(decoded_X_test_cpu.detach().numpy(), [-1, 28, 28]) * 255\n",
    "            figure = plt.figure(figsize=(20, 4))\n",
    "\n",
    "            for i in range (n_digits):\n",
    "                axis = plt.subplot(2, n_digits, i + 1)\n",
    "                X_test_cpu = X_test.cpu()\n",
    "                plt.imshow(X_test_cpu[i].reshape(28, 28).detach().numpy())\n",
    "                plt.gray()\n",
    "                axis.get_xaxis().set_visible(False)\n",
    "                axis.get_yaxis().set_visible(False)\n",
    "                \n",
    "                axis = plt.subplot(2, n_digits, i + 1 + n_digits)\n",
    "                plt.imshow(decoded_X_test_cpu[i])\n",
    "                plt.gray()\n",
    "                axis.get_xaxis().set_visible(False)\n",
    "                axis.get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.savefig('reconstruction_standard_aae_least/epoch_%d.png' % epoch)\n",
    "            plt.close('all')\n",
    "\n",
    "            z_sampling = [np.linspace(-3, 3, 10) for i in range (10)]\n",
    "\n",
    "            n_x, n_y = 10, 10\n",
    "            plt.subplot()\n",
    "            grid_spec = gridspec.GridSpec(n_x, n_y, hspace=0.05, wspace=0.05)\n",
    "\n",
    "            for i, j in enumerate(grid_spec):\n",
    "                latent_variable = np.concatenate([[z_i[np.random.randint(10)]] for z_i in z_sampling])\n",
    "                latent_variable = np.reshape(latent_variable, (-1, z_dimension))\n",
    "                latent_variable = torch.from_numpy(latent_variable).float().cuda(cuda)\n",
    "                \n",
    "                reconstructed_x = decoder(latent_variable)\n",
    "                reconstructed_x_cpu = reconstructed_x.cpu()\n",
    "                axis = plt.subplot(j)\n",
    "                image = np.array(reconstructed_x_cpu.detach().numpy().tolist()).reshape(28, 28)\n",
    "                axis.imshow(image, cmap='gray')\n",
    "                axis.set_xticks([])\n",
    "                axis.set_yticks([])\n",
    "                axis.set_aspect('auto')\n",
    "            \n",
    "            plt.savefig('sampling_standard_aae_least/epoch_%d.png' % epoch)\n",
    "            plt.close('all')\n",
    "\n",
    "            encoder = encoder.train()\n",
    "            decoder = decoder.train()\n",
    "            discriminator_gauss = discriminator_gauss.train()\n",
    "            \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/tensor.py:362: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0, Time-2.2e+01, Discriminator_loss-0.2448, Generator_loss-0.3138, reconstruction_loss-0.05374\n",
      "Epoch-10, Time-1.9e+01, Discriminator_loss-0.236, Generator_loss-0.1348, reconstruction_loss-0.02998\n",
      "Epoch-20, Time-1.9e+01, Discriminator_loss-0.2354, Generator_loss-0.1492, reconstruction_loss-0.02731\n",
      "Epoch-30, Time-1.8e+01, Discriminator_loss-0.2275, Generator_loss-0.135, reconstruction_loss-0.02785\n",
      "Epoch-40, Time-1.9e+01, Discriminator_loss-0.2298, Generator_loss-0.1612, reconstruction_loss-0.02779\n",
      "Epoch-50, Time-1.9e+01, Discriminator_loss-0.221, Generator_loss-0.1558, reconstruction_loss-0.02406\n",
      "Epoch-60, Time-1.8e+01, Discriminator_loss-0.213, Generator_loss-0.1459, reconstruction_loss-0.02613\n",
      "Epoch-70, Time-1.9e+01, Discriminator_loss-0.2024, Generator_loss-0.1487, reconstruction_loss-0.02359\n",
      "Epoch-80, Time-1.9e+01, Discriminator_loss-0.1937, Generator_loss-0.1795, reconstruction_loss-0.02205\n",
      "Epoch-90, Time-1.9e+01, Discriminator_loss-0.2036, Generator_loss-0.1675, reconstruction_loss-0.02414\n",
      "Epoch-100, Time-1.9e+01, Discriminator_loss-0.1933, Generator_loss-0.1658, reconstruction_loss-0.02557\n",
      "Epoch-110, Time-1.8e+01, Discriminator_loss-0.2141, Generator_loss-0.1773, reconstruction_loss-0.02424\n",
      "Epoch-120, Time-1.8e+01, Discriminator_loss-0.1832, Generator_loss-0.1681, reconstruction_loss-0.0243\n",
      "Epoch-130, Time-1.9e+01, Discriminator_loss-0.2011, Generator_loss-0.1744, reconstruction_loss-0.02293\n",
      "Epoch-140, Time-1.9e+01, Discriminator_loss-0.1753, Generator_loss-0.1724, reconstruction_loss-0.023\n",
      "Epoch-150, Time-1.8e+01, Discriminator_loss-0.1695, Generator_loss-0.1775, reconstruction_loss-0.02393\n",
      "Epoch-160, Time-1.9e+01, Discriminator_loss-0.2147, Generator_loss-0.1856, reconstruction_loss-0.02305\n",
      "Epoch-170, Time-1.9e+01, Discriminator_loss-0.199, Generator_loss-0.1828, reconstruction_loss-0.02363\n",
      "Epoch-180, Time-1.8e+01, Discriminator_loss-0.1987, Generator_loss-0.181, reconstruction_loss-0.02263\n",
      "Epoch-190, Time-2e+01, Discriminator_loss-0.2089, Generator_loss-0.1736, reconstruction_loss-0.02353\n",
      "Epoch-200, Time-2.1e+01, Discriminator_loss-0.1897, Generator_loss-0.1831, reconstruction_loss-0.0252\n",
      "Epoch-210, Time-1.9e+01, Discriminator_loss-0.1955, Generator_loss-0.1954, reconstruction_loss-0.02347\n",
      "Epoch-220, Time-1.9e+01, Discriminator_loss-0.176, Generator_loss-0.203, reconstruction_loss-0.02012\n",
      "Epoch-230, Time-1.9e+01, Discriminator_loss-0.1802, Generator_loss-0.2059, reconstruction_loss-0.02314\n",
      "Epoch-240, Time-1.9e+01, Discriminator_loss-0.1624, Generator_loss-0.2077, reconstruction_loss-0.02226\n",
      "Epoch-250, Time-1.8e+01, Discriminator_loss-0.1794, Generator_loss-0.1918, reconstruction_loss-0.0221\n",
      "Epoch-260, Time-1.8e+01, Discriminator_loss-0.1677, Generator_loss-0.214, reconstruction_loss-0.02358\n",
      "Epoch-270, Time-1.9e+01, Discriminator_loss-0.1617, Generator_loss-0.1772, reconstruction_loss-0.02325\n",
      "Epoch-280, Time-1.8e+01, Discriminator_loss-0.1716, Generator_loss-0.2014, reconstruction_loss-0.02306\n",
      "Epoch-290, Time-1.8e+01, Discriminator_loss-0.1942, Generator_loss-0.197, reconstruction_loss-0.02371\n",
      "Epoch-300, Time-1.9e+01, Discriminator_loss-0.1794, Generator_loss-0.1944, reconstruction_loss-0.02312\n",
      "Epoch-310, Time-1.9e+01, Discriminator_loss-0.1874, Generator_loss-0.2113, reconstruction_loss-0.02208\n",
      "Epoch-320, Time-1.9e+01, Discriminator_loss-0.1866, Generator_loss-0.2134, reconstruction_loss-0.02282\n",
      "Epoch-330, Time-1.9e+01, Discriminator_loss-0.1726, Generator_loss-0.2153, reconstruction_loss-0.02348\n",
      "Epoch-340, Time-1.9e+01, Discriminator_loss-0.176, Generator_loss-0.2158, reconstruction_loss-0.02245\n",
      "Epoch-350, Time-1.9e+01, Discriminator_loss-0.1685, Generator_loss-0.1977, reconstruction_loss-0.02236\n",
      "Epoch-360, Time-1.8e+01, Discriminator_loss-0.1715, Generator_loss-0.2191, reconstruction_loss-0.02397\n",
      "Epoch-370, Time-1.9e+01, Discriminator_loss-0.1732, Generator_loss-0.2094, reconstruction_loss-0.02108\n",
      "Epoch-380, Time-2e+01, Discriminator_loss-0.1674, Generator_loss-0.2101, reconstruction_loss-0.02203\n",
      "Epoch-390, Time-1.9e+01, Discriminator_loss-0.1628, Generator_loss-0.1926, reconstruction_loss-0.02323\n",
      "Epoch-400, Time-1.9e+01, Discriminator_loss-0.1733, Generator_loss-0.2131, reconstruction_loss-0.02246\n",
      "Epoch-410, Time-1.9e+01, Discriminator_loss-0.1834, Generator_loss-0.1843, reconstruction_loss-0.02217\n",
      "Epoch-420, Time-1.9e+01, Discriminator_loss-0.1721, Generator_loss-0.2229, reconstruction_loss-0.02179\n",
      "Epoch-430, Time-1.9e+01, Discriminator_loss-0.1712, Generator_loss-0.2068, reconstruction_loss-0.02306\n",
      "Epoch-440, Time-1.9e+01, Discriminator_loss-0.174, Generator_loss-0.2315, reconstruction_loss-0.02131\n",
      "Epoch-450, Time-1.9e+01, Discriminator_loss-0.1983, Generator_loss-0.2185, reconstruction_loss-0.02444\n",
      "Epoch-460, Time-1.9e+01, Discriminator_loss-0.1626, Generator_loss-0.2053, reconstruction_loss-0.02353\n",
      "Epoch-470, Time-1.9e+01, Discriminator_loss-0.1652, Generator_loss-0.2086, reconstruction_loss-0.02277\n",
      "Epoch-480, Time-1.9e+01, Discriminator_loss-0.1719, Generator_loss-0.2066, reconstruction_loss-0.02181\n",
      "Epoch-490, Time-1.8e+01, Discriminator_loss-0.1748, Generator_loss-0.2295, reconstruction_loss-0.02068\n",
      "Epoch-500, Time-1.9e+01, Discriminator_loss-0.1964, Generator_loss-0.2041, reconstruction_loss-0.02288\n",
      "Epoch-510, Time-1.9e+01, Discriminator_loss-0.1717, Generator_loss-0.213, reconstruction_loss-0.02189\n",
      "Epoch-520, Time-1.9e+01, Discriminator_loss-0.1632, Generator_loss-0.1974, reconstruction_loss-0.02316\n",
      "Epoch-530, Time-1.9e+01, Discriminator_loss-0.2162, Generator_loss-0.1899, reconstruction_loss-0.02197\n",
      "Epoch-540, Time-1.9e+01, Discriminator_loss-0.1906, Generator_loss-0.2157, reconstruction_loss-0.02146\n",
      "Epoch-550, Time-1.8e+01, Discriminator_loss-0.183, Generator_loss-0.2128, reconstruction_loss-0.0219\n",
      "Epoch-560, Time-1.9e+01, Discriminator_loss-0.1891, Generator_loss-0.1857, reconstruction_loss-0.02334\n",
      "Epoch-570, Time-1.9e+01, Discriminator_loss-0.1647, Generator_loss-0.2255, reconstruction_loss-0.02231\n",
      "Epoch-580, Time-1.9e+01, Discriminator_loss-0.1788, Generator_loss-0.2116, reconstruction_loss-0.02228\n",
      "Epoch-590, Time-1.9e+01, Discriminator_loss-0.1721, Generator_loss-0.2077, reconstruction_loss-0.02177\n",
      "Epoch-600, Time-1.9e+01, Discriminator_loss-0.1886, Generator_loss-0.2028, reconstruction_loss-0.02097\n",
      "Epoch-610, Time-1.9e+01, Discriminator_loss-0.161, Generator_loss-0.1947, reconstruction_loss-0.02456\n",
      "Epoch-620, Time-1.9e+01, Discriminator_loss-0.1905, Generator_loss-0.2252, reconstruction_loss-0.0222\n",
      "Epoch-630, Time-1.9e+01, Discriminator_loss-0.1554, Generator_loss-0.2286, reconstruction_loss-0.02171\n",
      "Epoch-640, Time-1.9e+01, Discriminator_loss-0.1957, Generator_loss-0.2277, reconstruction_loss-0.023\n",
      "Epoch-650, Time-1.8e+01, Discriminator_loss-0.1526, Generator_loss-0.2276, reconstruction_loss-0.02075\n",
      "Epoch-660, Time-1.8e+01, Discriminator_loss-0.1657, Generator_loss-0.194, reconstruction_loss-0.02259\n",
      "Epoch-670, Time-1.8e+01, Discriminator_loss-0.1822, Generator_loss-0.2129, reconstruction_loss-0.02275\n",
      "Epoch-680, Time-1.9e+01, Discriminator_loss-0.1744, Generator_loss-0.1974, reconstruction_loss-0.02422\n",
      "Epoch-690, Time-1.9e+01, Discriminator_loss-0.1733, Generator_loss-0.1979, reconstruction_loss-0.02076\n",
      "Epoch-700, Time-1.9e+01, Discriminator_loss-0.1615, Generator_loss-0.2266, reconstruction_loss-0.02322\n",
      "Epoch-710, Time-1.9e+01, Discriminator_loss-0.1568, Generator_loss-0.2218, reconstruction_loss-0.02165\n",
      "Epoch-720, Time-1.9e+01, Discriminator_loss-0.1587, Generator_loss-0.1932, reconstruction_loss-0.02178\n",
      "Epoch-730, Time-1.9e+01, Discriminator_loss-0.1559, Generator_loss-0.231, reconstruction_loss-0.02141\n",
      "Epoch-740, Time-1.8e+01, Discriminator_loss-0.2012, Generator_loss-0.2338, reconstruction_loss-0.02087\n",
      "Epoch-750, Time-1.8e+01, Discriminator_loss-0.1834, Generator_loss-0.2215, reconstruction_loss-0.02249\n",
      "Epoch-760, Time-1.9e+01, Discriminator_loss-0.1748, Generator_loss-0.1921, reconstruction_loss-0.02348\n",
      "Epoch-770, Time-1.9e+01, Discriminator_loss-0.1589, Generator_loss-0.2501, reconstruction_loss-0.02362\n",
      "Epoch-780, Time-1.9e+01, Discriminator_loss-0.1938, Generator_loss-0.2226, reconstruction_loss-0.02128\n",
      "Epoch-790, Time-1.9e+01, Discriminator_loss-0.1727, Generator_loss-0.1769, reconstruction_loss-0.02285\n",
      "Epoch-800, Time-1.9e+01, Discriminator_loss-0.16, Generator_loss-0.2104, reconstruction_loss-0.02274\n",
      "Epoch-810, Time-1.8e+01, Discriminator_loss-0.1712, Generator_loss-0.2138, reconstruction_loss-0.02256\n",
      "Epoch-820, Time-1.9e+01, Discriminator_loss-0.1982, Generator_loss-0.214, reconstruction_loss-0.02287\n",
      "Epoch-830, Time-1.9e+01, Discriminator_loss-0.1817, Generator_loss-0.1863, reconstruction_loss-0.02152\n",
      "Epoch-840, Time-1.8e+01, Discriminator_loss-0.1872, Generator_loss-0.2113, reconstruction_loss-0.02094\n",
      "Epoch-850, Time-1.9e+01, Discriminator_loss-0.1532, Generator_loss-0.2337, reconstruction_loss-0.02257\n",
      "Epoch-860, Time-1.9e+01, Discriminator_loss-0.1864, Generator_loss-0.2144, reconstruction_loss-0.02144\n",
      "Epoch-870, Time-1.9e+01, Discriminator_loss-0.1569, Generator_loss-0.207, reconstruction_loss-0.02081\n",
      "Epoch-880, Time-1.9e+01, Discriminator_loss-0.1918, Generator_loss-0.2119, reconstruction_loss-0.02174\n",
      "Epoch-890, Time-1.9e+01, Discriminator_loss-0.1588, Generator_loss-0.1976, reconstruction_loss-0.02185\n",
      "Epoch-900, Time-1.9e+01, Discriminator_loss-0.1586, Generator_loss-0.2251, reconstruction_loss-0.02328\n",
      "Epoch-910, Time-1.9e+01, Discriminator_loss-0.219, Generator_loss-0.1951, reconstruction_loss-0.02199\n",
      "Epoch-920, Time-1.9e+01, Discriminator_loss-0.1801, Generator_loss-0.2096, reconstruction_loss-0.02328\n",
      "Epoch-930, Time-1.9e+01, Discriminator_loss-0.1711, Generator_loss-0.2087, reconstruction_loss-0.02156\n",
      "Epoch-940, Time-1.8e+01, Discriminator_loss-0.1812, Generator_loss-0.2269, reconstruction_loss-0.02213\n",
      "Epoch-950, Time-1.9e+01, Discriminator_loss-0.1746, Generator_loss-0.2089, reconstruction_loss-0.02134\n",
      "Epoch-960, Time-1.9e+01, Discriminator_loss-0.1573, Generator_loss-0.2005, reconstruction_loss-0.02278\n",
      "Epoch-970, Time-1.8e+01, Discriminator_loss-0.1745, Generator_loss-0.2096, reconstruction_loss-0.02292\n",
      "Epoch-980, Time-1.9e+01, Discriminator_loss-0.1615, Generator_loss-0.2162, reconstruction_loss-0.02413\n",
      "Epoch-990, Time-1.8e+01, Discriminator_loss-0.1578, Generator_loss-0.2008, reconstruction_loss-0.02321\n"
     ]
    }
   ],
   "source": [
    "trained_encoder, trained_decoder = train_model(train_labeled_loader, train_unlabeled_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location_encoder = \"least-standard-encoder.pt\"\n",
    "file_location_decoder = \"least-standard-decoder.pt\"\n",
    "torch.save(trained_encoder.state_dict(), file_location_encoder)\n",
    "torch.save(trained_decoder.state_dict(), file_location_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
